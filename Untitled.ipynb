{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2e12cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import load, asarray, zeros, ones, savez_compressed\n",
    "from numpy.random import randn, randint\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Conv2D\n",
    "from tensorflow.keras.layers import UpSampling2D, AveragePooling2D, LeakyReLU, Layer, Add\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "import mtcnn\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from keras import backend\n",
    "from matplotlib import pyplot\n",
    "import cv2\n",
    "import os\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3adfcea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "tf.keras.utils.disable_interactive_logging()\n",
    "# policy = mixed_precision.Policy('mixed_float16')\n",
    "# mixed_precision.set_global_policy(policy)\n",
    "# print('Compute dtype: %s' % policy.compute_dtype)\n",
    "# print('Variable dtype: %s' % policy.variable_dtype)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93820e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the image file\n",
    "def load_image(filename):\n",
    "    image = Image.open(filename)\n",
    "    image = image.convert('RGB')\n",
    "    pixels = asarray(image)\n",
    "    pixels = cv2.resize(pixels, (256,256))\n",
    "    return pixels\n",
    "    \n",
    "# extract the face from a loaded image and resize\n",
    "def extract_face(model, pixels, required_size=(128, 128)):\n",
    "    # detect face in the image\n",
    "    faces = model.detect_faces(pixels)\n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "    \n",
    "    # extract details of the face\n",
    "    x1, y1, width, height = faces[0]['box']\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    \n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    face_pixels = pixels[y1:y2, x1:x2]\n",
    "    image = Image.fromarray(face_pixels)\n",
    "    image = image.resize(required_size)\n",
    "    face_array = asarray(image)\n",
    "    \n",
    "    return face_array\n",
    "    \n",
    "# load images and extract faces for all images in a directory\n",
    "def load_faces(directory, n_faces):\n",
    "    # prepare model\n",
    "#     model = MTCNN()\n",
    "    faces = list()\n",
    "    paths = os.listdir(directory)\n",
    "    random.shuffle(paths)\n",
    "    for filename in tqdm(paths):\n",
    "        # Computing the retrieval and extraction of faces\n",
    "        pixels = load_image(directory + filename)\n",
    "#         face = extract_face(model, pixels)\n",
    "#         if face is None:\n",
    "#             continue\n",
    "        faces.append(pixels)\n",
    "        #print(len(faces), face.shape)\n",
    "        if len(faces) >= n_faces:\n",
    "            break\n",
    "            \n",
    "    return asarray(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb4fc36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ad98d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load and extract all faces\n",
    "# directory = 'img_align_celeba/img_align_celeba/'\n",
    "# all_faces = load_faces(directory, 10000)\n",
    "# print('Loaded: ', all_faces.shape)\n",
    "\n",
    "# # save in compressed format\n",
    "# savez_compressed('img_align_celeba_128.npz', all_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4268df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel-wise feature vector normalization layer\n",
    "class PixelNormalization(Layer):\n",
    "    # initialize the layer\n",
    "    def __init__(self, **kwargs):\n",
    "        super(PixelNormalization, self).__init__(**kwargs)\n",
    " \n",
    "    # perform the operation\n",
    "    def call(self, inputs):\n",
    "        # computing pixel values\n",
    "        values = inputs**2.0\n",
    "        mean_values = backend.mean(values, axis=-1, keepdims=True)\n",
    "        mean_values += 1.0e-8\n",
    "        l2 = backend.sqrt(mean_values)\n",
    "        normalized = inputs / l2\n",
    "        return normalized\n",
    " \n",
    "    # define the output shape of the layer\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dfe3edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini-batch standard deviation layer\n",
    "class MinibatchStdev(Layer):\n",
    "    # initialize the layer\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MinibatchStdev, self).__init__(**kwargs)\n",
    " \n",
    "    # perform the operation\n",
    "    def call(self, inputs):\n",
    "        mean = backend.mean(inputs, axis=0, keepdims=True)\n",
    "        squ_diffs = backend.square(inputs - mean)\n",
    "        mean_sq_diff = backend.mean(squ_diffs, axis=0, keepdims=True)\n",
    "        mean_sq_diff += 1e-8\n",
    "        stdev = backend.sqrt(mean_sq_diff)\n",
    "        \n",
    "        mean_pix = backend.mean(stdev, keepdims=True)\n",
    "        shape = backend.shape(inputs)\n",
    "        output = backend.tile(mean_pix, (shape[0], shape[1], shape[2], 1))\n",
    "        \n",
    "        combined = backend.concatenate([inputs, output], axis=-1)\n",
    "        return combined\n",
    " \n",
    "    # define the output shape of the layer\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        input_shape = list(input_shape)\n",
    "        input_shape[-1] += 1\n",
    "        return tuple(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f8daa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted sum output\n",
    "class WeightedSum(Add):\n",
    "    # init with default value\n",
    "    def __init__(self, alpha=0.0, **kwargs):\n",
    "        super(WeightedSum, self).__init__(**kwargs)\n",
    "        self.alpha = backend.variable(alpha, name='ws_alpha')\n",
    " \n",
    "    # output a weighted sum of inputs\n",
    "    def _merge_function(self, inputs):\n",
    "        # only supports a weighted sum of two inputs\n",
    "        assert (len(inputs) == 2)\n",
    "        # ((1-a) * input1) + (a * input2)\n",
    "        output = ((1.0 - self.alpha) * inputs[0]) + (self.alpha * inputs[1])\n",
    "        return output\n",
    "\n",
    "# calculate wasserstein loss\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return backend.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47adad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "def load_real_samples(filename):\n",
    "    data = load(filename)\n",
    "    X = data['arr_0']\n",
    "    X = X.astype('float32')\n",
    "    X = (X - 127.5) / 127.5\n",
    "    return X\n",
    " \n",
    "# select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    X = dataset[ix]\n",
    "    X = (X - 127.5) / 127.5\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y\n",
    " \n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    " \n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    X = generator.predict(x_input, verbose = 0)\n",
    "    y = -ones((n_samples, 1))\n",
    "    return X, y\n",
    " \n",
    "# update the alpha value on each instance of WeightedSum\n",
    "def update_fadein(models, step, n_steps):\n",
    "    alpha = step / float(n_steps - 1)\n",
    "    for model in models:\n",
    "        for layer in model.layers:\n",
    "            if isinstance(layer, WeightedSum):\n",
    "                backend.set_value(layer.alpha, alpha)\n",
    "                \n",
    "# scale images to preferred size\n",
    "def scale_dataset(images, new_shape):\n",
    "    images_list = list()\n",
    "    for image in images:\n",
    "        new_image = resize(image, new_shape, 0)\n",
    "        images_list.append(new_image)\n",
    "    return asarray(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae9788ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a generator block\n",
    "def add_generator_block(old_model, stage, n_blocks):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    const = max_norm(1.0)\n",
    "    block_end = old_model.layers[-2].output\n",
    "    if stage<=3:\n",
    "    # upsample, and define new block\n",
    "        upsampling = UpSampling2D()(block_end)\n",
    "        g = Conv2D(512, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(upsampling)\n",
    "        g = PixelNormalization()(g)\n",
    "        g = LeakyReLU(alpha=0.2)(g)\n",
    "        g = Conv2D(512, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "        g = PixelNormalization()(g)\n",
    "        g = LeakyReLU(alpha=0.2)(g)\n",
    "\n",
    "        out_image = Conv2D(3, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "        model1 = Model(old_model.input, out_image)\n",
    "        out_old = old_model.layers[-1]\n",
    "        out_image2 = out_old(upsampling)\n",
    "\n",
    "        merged = WeightedSum()([out_image2, out_image])\n",
    "        model2 = Model(old_model.input, merged)\n",
    "    else:\n",
    "        # upsample, and define new block\n",
    "        upsampling = UpSampling2D()(block_end)\n",
    "        g = Conv2D(16 * (2**(n_blocks-stage)) , (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(upsampling)\n",
    "        g = PixelNormalization()(g)\n",
    "        g = LeakyReLU(alpha=0.2)(g)\n",
    "        g = Conv2D(16 * (2**(n_blocks-stage)), (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "        g = PixelNormalization()(g)\n",
    "        g = LeakyReLU(alpha=0.2)(g)\n",
    "\n",
    "        out_image = Conv2D(3, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "        model1 = Model(old_model.input, out_image)\n",
    "        out_old = old_model.layers[-1]\n",
    "        out_image2 = out_old(upsampling)\n",
    "\n",
    "        merged = WeightedSum()([out_image2, out_image])\n",
    "        model2 = Model(old_model.input, merged)\n",
    "    return [model1, model2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ad5384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generator models\n",
    "def define_generator(latent_dim, n_blocks, in_dim=4):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    const = max_norm(1.0)\n",
    "    model_list = list()\n",
    "    in_latent = Input(shape=(latent_dim,))\n",
    "    g  = Dense(128 * in_dim * in_dim, kernel_initializer=init, kernel_constraint=const)(in_latent)\n",
    "    g = Reshape((in_dim, in_dim, 128))(g)\n",
    "    \n",
    "    # conv 4x4, input block\n",
    "    g = Conv2D(512, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    \n",
    "    # conv 3x3\n",
    "    g = Conv2D(512, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    \n",
    "    # conv 1x1, output block\n",
    "    out_image = Conv2D(3, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    model = Model(in_latent, out_image)\n",
    "    model_list.append([model, model])\n",
    "    \n",
    "    for i in range(1, n_blocks):\n",
    "        old_model = model_list[i - 1][0]\n",
    "        models = add_generator_block(old_model,i,n_blocks)\n",
    "        model_list.append(models)\n",
    "        \n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8584361a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a generator block\n",
    "def add_generator_block(old_model):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    const = max_norm(1.0)\n",
    "    block_end = old_model.layers[-2].output\n",
    "    \n",
    "    # upsample, and define new block\n",
    "    upsampling = UpSampling2D()(block_end)\n",
    "    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(upsampling)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    \n",
    "    out_image = Conv2D(3, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    model1 = Model(old_model.input, out_image)\n",
    "    out_old = old_model.layers[-1]\n",
    "    out_image2 = out_old(upsampling)\n",
    "    \n",
    "    merged = WeightedSum()([out_image2, out_image])\n",
    "    model2 = Model(old_model.input, merged)\n",
    "    return [model1, model2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd3535e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generator models\n",
    "def define_generator(latent_dim, n_blocks, in_dim=4):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    const = max_norm(1.0)\n",
    "    model_list = list()\n",
    "    in_latent = Input(shape=(latent_dim,))\n",
    "    g  = Dense(128 * in_dim * in_dim, kernel_initializer=init, kernel_constraint=const)(in_latent)\n",
    "    g = Reshape((in_dim, in_dim, 128))(g)\n",
    "    \n",
    "    # conv 4x4, input block\n",
    "    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    \n",
    "    # conv 3x3\n",
    "    g = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    g = PixelNormalization()(g)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    \n",
    "    # conv 1x1, output block\n",
    "    out_image = Conv2D(3, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
    "    model = Model(in_latent, out_image)\n",
    "    model_list.append([model, model])\n",
    "    \n",
    "    for i in range(1, n_blocks):\n",
    "        old_model = model_list[i - 1][0]\n",
    "        models = add_generator_block(old_model)\n",
    "        model_list.append(models)\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74c07f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a discriminator block\n",
    "def add_discriminator_block(old_model, n_input_layers=3):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    const = max_norm(1.0)\n",
    "    in_shape = list(old_model.input.shape)\n",
    "    \n",
    "    # define new input shape as double the size\n",
    "    input_shape = (in_shape[-2]*2, in_shape[-2]*2, in_shape[-1])\n",
    "    in_image = Input(shape=input_shape)\n",
    "    \n",
    "    # define new input processing layer\n",
    "    d = Conv2D(128, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(in_image)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    # define new block\n",
    "    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = AveragePooling2D()(d)\n",
    "    block_new = d\n",
    "    \n",
    "    # skip the input, 1x1 and activation for the old model\n",
    "    for i in range(n_input_layers, len(old_model.layers)):\n",
    "        d = old_model.layers[i](d)\n",
    "    model1 = Model(in_image, d)\n",
    "    \n",
    "    model1.compile(loss=wasserstein_loss, optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "    \n",
    "    downsample = AveragePooling2D()(in_image)\n",
    "    \n",
    "    block_old = old_model.layers[1](downsample)\n",
    "    block_old = old_model.layers[2](block_old)\n",
    "    d = WeightedSum()([block_old, block_new])\n",
    "    \n",
    "    for i in range(n_input_layers, len(old_model.layers)):\n",
    "        d = old_model.layers[i](d)\n",
    "        \n",
    "    model2 = Model(in_image, d)\n",
    "    \n",
    "    model2.compile(loss=wasserstein_loss, optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "    return [model1, model2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "228aa26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the discriminator models for each image resolution\n",
    "def define_discriminator(n_blocks, input_shape=(4,4,3)):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    const = max_norm(1.0)\n",
    "    model_list = list()\n",
    "    in_image = Input(shape=input_shape)\n",
    "    \n",
    "    d = Conv2D(128, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(in_image)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = MinibatchStdev()(d)\n",
    "    \n",
    "    d = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    d = Conv2D(128, (4,4), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    d = Flatten()(d)\n",
    "    out_class = Dense(1)(d)\n",
    "    \n",
    "    model = Model(in_image, out_class)\n",
    "    model.compile(loss=wasserstein_loss, optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "    model_list.append([model, model])\n",
    "    \n",
    "    for i in range(1, n_blocks):\n",
    "        old_model = model_list[i - 1][0]\n",
    "        models = add_discriminator_block(old_model)\n",
    "        model_list.append(models)\n",
    "        \n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc99cf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define composite models for training generators via discriminators\n",
    "\n",
    "def define_composite(discriminators, generators):\n",
    "    model_list = list()\n",
    "    # create composite models\n",
    "    for i in range(len(discriminators)):\n",
    "        g_models, d_models = generators[i], discriminators[i]\n",
    "        # straight-through model\n",
    "        d_models[0].trainable = False\n",
    "        model1 = Sequential()\n",
    "        model1.add(g_models[0])\n",
    "        model1.add(d_models[0])\n",
    "        model1.compile(loss=wasserstein_loss, optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "        # fade-in model\n",
    "        d_models[1].trainable = False\n",
    "        model2 = Sequential()\n",
    "        model2.add(g_models[1])\n",
    "        model2.add(d_models[1])\n",
    "        model2.compile(loss=wasserstein_loss, optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
    "        # store\n",
    "        model_list.append([model1, model2])\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d75873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a generator and discriminator\n",
    "def train_epochs(g_model, d_model, gan_model, dataset, n_epochs, n_batch, fadein=False):\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    n_steps = bat_per_epo #* n_epochs\n",
    "    half_batch = int(n_batch / 2)\n",
    "    \n",
    "    for i in tqdm(range(n_steps)):\n",
    "        # update alpha for all WeightedSum layers when fading in new blocks\n",
    "        if fadein:\n",
    "            update_fadein([g_model, d_model, gan_model], i, n_steps)\n",
    "        # prepare real and fake samples\n",
    "        X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "        X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "        \n",
    "        # update discriminator model\n",
    "        d_loss1 = d_model.train_on_batch(X_real, y_real)\n",
    "        d_loss2 = d_model.train_on_batch(X_fake, y_fake)\n",
    "        \n",
    "        # update the generator via the discriminator's error\n",
    "        z_input = generate_latent_points(latent_dim, n_batch)\n",
    "        y_real2 = ones((n_batch, 1))\n",
    "        g_loss = gan_model.train_on_batch(z_input, y_real2)\n",
    "        \n",
    "        # summarize loss on this batch\n",
    "        #print('>%d, d1=%.3f, d2=%.3f g=%.3f' % (i+1, d_loss1, d_loss2, g_loss))\n",
    "        \n",
    "# train the generator and discriminator\n",
    "def train(g_models, d_models, gan_models, directory, latent_dim, e_norm, e_fadein, n_batch, start_at):\n",
    "    if start_at == 0:\n",
    "        g_normal, d_normal, gan_normal = g_models[0][0], d_models[0][0], gan_models[0][0]\n",
    "        gen_shape = g_normal.output_shape\n",
    "        dataset = load_faces(directory, 10000)\n",
    "        scaled_data = scale_dataset(dataset, gen_shape[1:])\n",
    "        for k in range(e_norm[0]):\n",
    "            for j in range(1):\n",
    "                \n",
    "                \n",
    "                print('Scaled Data', scaled_data.shape)\n",
    "\n",
    "                # train normal or straight-through models\n",
    "                train_epochs(g_normal, d_normal, gan_normal, scaled_data, 1, n_batch[0])\n",
    "                summarize_performance('tuned', g_normal, latent_dim)\n",
    "\n",
    "        # process each level of growth\n",
    "        for i in range(1, len(g_models)):\n",
    "            # retrieve models for this level of growth\n",
    "            [g_normal, g_fadein] = g_models[i]\n",
    "            [d_normal, d_fadein] = d_models[i]\n",
    "            [gan_normal, gan_fadein] = gan_models[i]\n",
    "            gen_shape = g_normal.output_shape\n",
    "            scaled_data = scale_dataset(dataset, gen_shape[1:])\n",
    "            for k in range(e_norm[i]):\n",
    "                for j in range(1):\n",
    "                # scale dataset to appropriate size\n",
    "                    \n",
    "                    \n",
    "                    print('Scaled Data', scaled_data.shape)\n",
    "\n",
    "                    # train fade-in models for next level of growth\n",
    "                    train_epochs(g_fadein, d_fadein, gan_fadein, scaled_data, e_fadein[i], n_batch[i], True)\n",
    "                    summarize_performance('faded', g_fadein, latent_dim)\n",
    "\n",
    "                    # train normal or straight-through models\n",
    "                    train_epochs(g_normal, d_normal, gan_normal, scaled_data, e_norm[i], n_batch[i])\n",
    "                    summarize_performance('tuned', g_normal, latent_dim)\n",
    "    else:\n",
    "        dataset = load_faces(directory, 10000)\n",
    "        # process each level of growth\n",
    "        for i in range(start_at, len(g_models)):\n",
    "            # retrieve models for this level of growth\n",
    "            [g_normal, g_fadein] = g_models[i]\n",
    "            [d_normal, d_fadein] = d_models[i]\n",
    "            [gan_normal, gan_fadein] = gan_models[i]\n",
    "            gen_shape = g_normal.output_shape\n",
    "            scaled_data = scale_dataset(dataset, gen_shape[1:])\n",
    "            for k in range(e_norm[i]):\n",
    "                for j in range(1):\n",
    "                # scale dataset to appropriate size\n",
    "                    \n",
    "                    \n",
    "                    print('Scaled Data', scaled_data.shape)\n",
    "\n",
    "                    # train fade-in models for next level of growth\n",
    "                    train_epochs(g_fadein, d_fadein, gan_fadein, scaled_data, e_fadein[i], n_batch[i], True)\n",
    "                    summarize_performance('faded', g_fadein, latent_dim)\n",
    "\n",
    "                    # train normal or straight-through models\n",
    "                    train_epochs(g_normal, d_normal, gan_normal, scaled_data, e_norm[i], n_batch[i])\n",
    "                    summarize_performance('tuned', g_normal, latent_dim)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58f93c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate samples and save as a plot and save the model\n",
    "def summarize_performance(status, g_model, latent_dim, n_samples=25):\n",
    "    gen_shape = g_model.output_shape\n",
    "    name = '%03dx%03d-%s' % (gen_shape[1], gen_shape[2], status)\n",
    "    \n",
    "    X, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
    "    X = (X - X.min()) / (X.max() - X.min())\n",
    "    \n",
    "    square = int(sqrt(n_samples))\n",
    "    for i in range(n_samples):\n",
    "        pyplot.subplot(square, square, 1 + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(X[i])\n",
    "        \n",
    "    # save plot to file\n",
    "    filename1 = 'plot_%s.png' % (name)\n",
    "    pyplot.savefig(filename1)\n",
    "    pyplot.close()\n",
    "    \n",
    "    filename2 = 'model_%s.h5' % (name)\n",
    "    g_model.save(filename2)\n",
    "    filename3 = 'model_%s_weights.h5' % (name)\n",
    "    g_model.save_weights(filename3)\n",
    "    print('>Saved: %s and %s' % (filename1, filename2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b7a273e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boude\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n",
      "C:\\Users\\boude\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# number of growth phases where 6 blocks == [4, 8, 16, 32, 64, 128]\n",
    "n_blocks = 8\n",
    "latent_dim = 100\n",
    "\n",
    "d_models = define_discriminator(n_blocks)\n",
    "g_models = define_generator(latent_dim, n_blocks)\n",
    "# g_models[0][1].load_weights(\"model_004x004-tuned_weights.h5\")\n",
    "# g_models[1][0].load_weights(\"model_008x008-tuned_weights.h5\")\n",
    "# g_models[1][1].load_weights(\"model_008x008-faded_weights.h5\")\n",
    "# g_models[2][0].load_weights(\"model_016x016-tuned_weights.h5\")\n",
    "# g_models[2][1].load_weights(\"model_016x016-faded_weights.h5\")\n",
    "# g_models[3][0].load_weights(\"model_032x032-tuned_weights.h5\")\n",
    "# g_models[3][1].load_weights(\"model_032x032-faded_weights.h5\")\n",
    "gan_models = define_composite(d_models, g_models)\n",
    "start_at = 0\n",
    "# dataset = load_real_samples('img_align_celeba_128.npz')\n",
    "# print('Loaded', dataset.shape)\n",
    "\n",
    "directory = 'img_align_celeba/img_align_celeba/'\n",
    "n_batch = [16, 16, 16, 16, 16, 16, 8, 4]\n",
    "n_epochs = [5, 8, 8, 10, 10, 10, 10, 15]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320f24db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▋                                                                      | 9999/202599 [05:26<1:44:54, 30.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Data (10000, 4, 4, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:07<00:00,  9.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_004x004-tuned.png and model_004x004-tuned.h5\n",
      "Scaled Data (10000, 4, 4, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:04<00:00,  9.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_004x004-tuned.png and model_004x004-tuned.h5\n",
      "Scaled Data (10000, 4, 4, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:04<00:00,  9.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_004x004-tuned.png and model_004x004-tuned.h5\n",
      "Scaled Data (10000, 4, 4, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:02<00:00, 10.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_004x004-tuned.png and model_004x004-tuned.h5\n",
      "Scaled Data (10000, 4, 4, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:05<00:00,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_004x004-tuned.png and model_004x004-tuned.h5\n",
      "Scaled Data (10000, 8, 8, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:21<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_008x008-faded.png and model_008x008-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:15<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_008x008-tuned.png and model_008x008-tuned.h5\n",
      "Scaled Data (10000, 8, 8, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:21<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_008x008-faded.png and model_008x008-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:14<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_008x008-tuned.png and model_008x008-tuned.h5\n",
      "Scaled Data (10000, 8, 8, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:20<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_008x008-faded.png and model_008x008-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:15<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_008x008-tuned.png and model_008x008-tuned.h5\n",
      "Scaled Data (10000, 8, 8, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:21<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_008x008-faded.png and model_008x008-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:14<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_008x008-tuned.png and model_008x008-tuned.h5\n",
      "Scaled Data (10000, 8, 8, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:20<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_008x008-faded.png and model_008x008-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:13<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_008x008-tuned.png and model_008x008-tuned.h5\n",
      "Scaled Data (10000, 8, 8, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:20<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_008x008-faded.png and model_008x008-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:15<00:00,  8.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_008x008-tuned.png and model_008x008-tuned.h5\n",
      "Scaled Data (10000, 8, 8, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:20<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_008x008-faded.png and model_008x008-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:14<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_008x008-tuned.png and model_008x008-tuned.h5\n",
      "Scaled Data (10000, 8, 8, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:21<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_008x008-faded.png and model_008x008-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:14<00:00,  8.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_008x008-tuned.png and model_008x008-tuned.h5\n",
      "Scaled Data (10000, 16, 16, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:30<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_016x016-faded.png and model_016x016-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:25<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_016x016-tuned.png and model_016x016-tuned.h5\n",
      "Scaled Data (10000, 16, 16, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:29<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_016x016-faded.png and model_016x016-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:27<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_016x016-tuned.png and model_016x016-tuned.h5\n",
      "Scaled Data (10000, 16, 16, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:32<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_016x016-faded.png and model_016x016-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:25<00:00,  7.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_016x016-tuned.png and model_016x016-tuned.h5\n",
      "Scaled Data (10000, 16, 16, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:29<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_016x016-faded.png and model_016x016-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:24<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_016x016-tuned.png and model_016x016-tuned.h5\n",
      "Scaled Data (10000, 16, 16, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:27<00:00,  7.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_016x016-faded.png and model_016x016-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:25<00:00,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_016x016-tuned.png and model_016x016-tuned.h5\n",
      "Scaled Data (10000, 16, 16, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:32<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_016x016-faded.png and model_016x016-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:25<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_016x016-tuned.png and model_016x016-tuned.h5\n",
      "Scaled Data (10000, 16, 16, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:35<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_016x016-faded.png and model_016x016-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:27<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_016x016-tuned.png and model_016x016-tuned.h5\n",
      "Scaled Data (10000, 16, 16, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:34<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_016x016-faded.png and model_016x016-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:28<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_016x016-tuned.png and model_016x016-tuned.h5\n",
      "Scaled Data (10000, 32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:33<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_032x032-faded.png and model_032x032-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:32<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_032x032-tuned.png and model_032x032-tuned.h5\n",
      "Scaled Data (10000, 32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:40<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_032x032-faded.png and model_032x032-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:42<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_032x032-tuned.png and model_032x032-tuned.h5\n",
      "Scaled Data (10000, 32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:45<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_032x032-faded.png and model_032x032-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:44<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_032x032-tuned.png and model_032x032-tuned.h5\n",
      "Scaled Data (10000, 32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:53<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_032x032-faded.png and model_032x032-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [01:53<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_032x032-tuned.png and model_032x032-tuned.h5\n",
      "Scaled Data (10000, 32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [02:05<00:00,  4.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_032x032-faded.png and model_032x032-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [02:04<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_032x032-tuned.png and model_032x032-tuned.h5\n",
      "Scaled Data (10000, 32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [02:16<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_032x032-faded.png and model_032x032-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [02:19<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_032x032-tuned.png and model_032x032-tuned.h5\n",
      "Scaled Data (10000, 32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [02:29<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_032x032-faded.png and model_032x032-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [02:32<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_032x032-tuned.png and model_032x032-tuned.h5\n",
      "Scaled Data (10000, 32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [02:45<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_032x032-faded.png and model_032x032-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [03:00<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_032x032-tuned.png and model_032x032-tuned.h5\n",
      "Scaled Data (10000, 32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [03:25<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_032x032-faded.png and model_032x032-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [03:30<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_032x032-tuned.png and model_032x032-tuned.h5\n",
      "Scaled Data (10000, 32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [03:49<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_032x032-faded.png and model_032x032-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [03:56<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_032x032-tuned.png and model_032x032-tuned.h5\n",
      "Scaled Data (10000, 64, 64, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [05:43<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_064x064-faded.png and model_064x064-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [05:20<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_064x064-tuned.png and model_064x064-tuned.h5\n",
      "Scaled Data (10000, 64, 64, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [05:37<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_064x064-faded.png and model_064x064-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [05:33<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_064x064-tuned.png and model_064x064-tuned.h5\n",
      "Scaled Data (10000, 64, 64, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [06:10<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_064x064-faded.png and model_064x064-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [06:28<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_064x064-tuned.png and model_064x064-tuned.h5\n",
      "Scaled Data (10000, 64, 64, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [06:28<00:00,  1.61it/s]\n",
      "c:\\users\\boude\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\matplotlib\\cm.py:440: RuntimeWarning: invalid value encountered in cast\n",
      "  xx = (xx * 255).astype(np.uint8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_064x064-faded.png and model_064x064-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [06:59<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_064x064-tuned.png and model_064x064-tuned.h5\n",
      "Scaled Data (10000, 64, 64, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [07:42<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_064x064-faded.png and model_064x064-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [07:44<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_064x064-tuned.png and model_064x064-tuned.h5\n",
      "Scaled Data (10000, 64, 64, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [08:07<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_064x064-faded.png and model_064x064-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [08:20<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_064x064-tuned.png and model_064x064-tuned.h5\n",
      "Scaled Data (10000, 64, 64, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 625/625 [13:17<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      ">Saved: plot_064x064-faded.png and model_064x064-faded.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████████████████████████████████████████▌     | 583/625 [07:25<00:34,  1.21it/s]"
     ]
    }
   ],
   "source": [
    "train(g_models, d_models, gan_models, directory, latent_dim, n_epochs, n_epochs, n_batch, start_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fd458b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d604bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2087a5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
